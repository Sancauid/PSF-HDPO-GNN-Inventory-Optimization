# PSF-HDPO-GNN-Inventory-Optimization

This repository contains a clean-room implementation of the Hindsight Differentiable Policy Optimization (HDPO) framework for inventory management, with a focus on Graph Neural Network (GNN) architectures using PyTorch Geometric.

## 1. Project Goal

The primary objective of this project is to replicate and extend the research from the paper "Deep Reinforcement Learning for Inventory Networks: Toward Reliable Policy Optimization" by Alvo et al. 

This implementation leverages PyTorch Geometric to create a more efficient, scalable, and memory-friendly training pipeline that does not rely on manual padding or masking for handling variable-size inventory networks.

## 2. Current Status

- **Framework:** A complete, end-to-end training pipeline has been developed.
- **Data Handling:** A PyG-native `DataLoader` has been implemented, which processes scenarios generated by the original project's `Scenario` class.
- **Models:** Initial versions of both a `Vanilla MLP` and a `SimpleGNN` policy network are implemented.
- **Training:** The training loop correctly simulates full episodes and uses a cost-minimization objective, replicating the core HDPO logic.

## 3. How to Run

### 3.1. Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/Sancauid/PSF-HDPO-GNN-Inventory-Optimization.git
    cd PSF-HDPO-GNN-Inventory-Optimization
    ```

2.  **Activate Conda Environment:**
    This project uses the `pyg_env` environment with PyTorch and PyTorch Geometric.
    ```bash
    conda activate pyg_env
    ```

### 3.2. Running an Experiment

Experiments are launched via the `main.py` script, which requires a setting and a hyperparameter configuration file.

```bash
# Example: Run the Vanilla MLP model for 20 epochs
python main.py path/to/config_setting.yml path/to/config_hyperparams.yml --model vanilla --epochs 20

# Example: Run the GNN model
python main.py path/to/config_setting.yml path/to/config_hyperparams.yml --model gnn --epochs 20